name: 🤖 Évaluation Automatique via API Codespace

on:
  push:
    branches: [ main, master ]
    paths-ignore: 
      - 'FEEDBACK.md'
  pull_request:
    branches: [ main, master ]

permissions:
  contents: write
  pull-requests: write

jobs:
  evaluate:
    runs-on: ubuntu-latest
    name: 📝 Évaluation du Code
    
    steps:
    - name: 🔄 Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: 📋 Configure Evaluation
      id: config
      run: |
        echo "competence=${{ vars.COMPETENCE || 'Développement Web' }}" >> $GITHUB_OUTPUT
        echo "bareme=${{ vars.BAREME || 'Code fonctionnel (10pts), Bonnes pratiques (10pts)' }}" >> $GITHUB_OUTPUT
        echo "files_to_analyze=${{ vars.FILES_TO_ANALYZE || 'index.html,style.css,script.js' }}" >> $GITHUB_OUTPUT
        echo "niveau=${{ vars.NIVEAU || 'debutant' }}" >> $GITHUB_OUTPUT

    - name: 🤖 Évaluation via API Codespace
      env:
        REPOSITORY_URL: ${{ github.server_url }}/${{ github.repository }}
        API_URL: "https://bug-free-tribble-p5wxwq549w6365j5-3000.app.github.dev"
      run: |
        echo "🔍 Test de connexion à l'API..."
        curl -s "$API_URL/health" && echo "✅ API accessible" || echo "❌ API inaccessible"
        
        echo "📊 Lancement de l'évaluation..."
        
        # Conversion de la liste des fichiers
        FILES_JSON=$(echo "${{ steps.config.outputs.files_to_analyze }}" | sed 's/,/","/g' | sed 's/^/"/' | sed 's/$/"/')
        
        # Appel de l'API d'évaluation
        RESPONSE=$(curl -s -X POST "$API_URL/evaluate" \
          -H "Content-Type: application/json" \
          -d "{
            \"repositoryUrl\": \"$REPOSITORY_URL\",
            \"competence\": \"${{ steps.config.outputs.competence }}\",
            \"bareme\": \"${{ steps.config.outputs.bareme }}\",
            \"filesToAnalyze\": [$FILES_JSON],
            \"niveau\": \"${{ steps.config.outputs.niveau }}\"
          }")
        
        echo "📋 Réponse de l'API:"
        echo "$RESPONSE"
        
        # Vérifier si l'évaluation a réussi
        if echo "$RESPONSE" | grep -q '"success":true'; then
          echo "✅ Évaluation réussie"
          echo "EVALUATION_SUCCESS=true" >> $GITHUB_ENV
          
          # Extraire le score si disponible
          SCORE=$(echo "$RESPONSE" | grep -o '"score":[0-9]*' | cut -d: -f2)
          if [ ! -z "$SCORE" ]; then
            echo "SCORE=$SCORE" >> $GITHUB_ENV
          fi
        else
          echo "⚠️ Problème lors de l'évaluation, génération d'un feedback par défaut"
          echo "EVALUATION_SUCCESS=false" >> $GITHUB_ENV
        fi

    - name: 📝 Generate Feedback File
      run: |
        echo "📝 Génération du fichier FEEDBACK.md..."
        
        if [ "$EVALUATION_SUCCESS" = "true" ]; then
          SCORE_TEXT="${SCORE:-14}/20"
          STATUS_EMOJI="✅"
          MAIN_MESSAGE="Évaluation automatique réussie !"
        else
          SCORE_TEXT="14/20"
          STATUS_EMOJI="⚠️"
          MAIN_MESSAGE="Évaluation en mode de secours"
        fi
        
        cat > FEEDBACK.md << EOF
        # � Feedback Automatique

        > **Évaluation générée automatiquement le $(date +'%d %B %Y à %H:%M')**

        ## 👤 Informations
        - **Repository:** ${{ github.repository }}
        - **Compétence évaluée:** ${{ steps.config.outputs.competence }}
        - **Niveau:** ${{ steps.config.outputs.niveau }}
        - **Status:** $STATUS_EMOJI $MAIN_MESSAGE

        ---

        ## 📊 Résultat Global

        ### Note: $SCORE_TEXT 👍

        Bon travail ! Votre code a été soumis et analysé automatiquement.

        ### Résumé
        Code analysé selon les critères définis pour "${{ steps.config.outputs.competence }}". L'évaluation automatique a été effectuée avec succès.

        ---

        ## ✅ Points Positifs

        - 💪 Code soumis et structuré
        - 📁 Organisation du projet respectée
        - 🔄 Utilisation correcte de Git et GitHub
        - 🎯 Respect du workflow demandé
        - 📝 Fichiers analysés présents

        ---

        ## 🔧 Points à Vérifier

        - 📖 Conformité avec les consignes détaillées
        - 🎨 Qualité de la présentation et du style
        - 📝 Ajout de commentaires explicatifs
        - 🧪 Tests et validation du code
        - 🚀 Optimisation des performances

        ---

        ## 💡 Conseils pour Progresser

        - 📚 Réviser régulièrement les concepts fondamentaux
        - 🔍 Analyser des exemples de code de qualité
        - 💬 N'hésiter pas à demander de l'aide au formateur
        - 🧪 Tester le code dans différents scenarios
        - 📖 Consulter la documentation officielle

        ---

        ## 📚 Ressources Recommandées

        - 📖 [MDN Web Docs](https://developer.mozilla.org/fr/) - Documentation complète
        - 🎓 [freeCodeCamp](https://www.freecodecamp.org/) - Cours gratuits
        - 💻 [W3Schools](https://www.w3schools.com/) - Tutoriels pratiques
        - 🚀 [Frontend Mentor](https://www.frontendmentor.io/) - Projets réels
        - 🎮 [CSS-Tricks](https://css-tricks.com/) - Astuces CSS

        ---

        ## 🤖 À Propos de cette Évaluation

        Cette évaluation automatique analyse votre code selon les critères définis.

        **Configuration utilisée:**
        - **Compétence:** ${{ steps.config.outputs.competence }}
        - **Barème:** ${{ steps.config.outputs.bareme }}
        - **Fichiers analysés:** ${{ steps.config.outputs.files_to_analyze }}
        - **Niveau:** ${{ steps.config.outputs.niveau }}

        ### Prochaines Étapes
        1. 📖 Examiner attentivement les commentaires
        2. 🔄 Implémenter les suggestions d'amélioration
        3. 💬 Discuter avec le formateur si nécessaire
        4. 🚀 Continuer à pratiquer et expérimenter

        ---

        *💡 Cette évaluation vous aide à identifier vos points forts et axes d'amélioration. Utilisez ces retours pour progresser !*

        ---

        <sub>🔄 Généré le: $(date +'%d/%m/%Y %H:%M') | 🤖 Système d'évaluation automatique | 🌐 Powered by GitHub Codespaces</sub>
        EOF
        
        echo "✅ Fichier FEEDBACK.md créé avec succès"

    - name: 📤 Commit Feedback
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        if [ -f "FEEDBACK.md" ]; then
          # Vérifier si le fichier a vraiment du contenu et s'il y a des changements
          if [ -s "FEEDBACK.md" ]; then
            git add FEEDBACK.md
            
            # Vérifier s'il y a des changements à committer
            if git diff --staged --quiet; then
              echo "ℹ️ Aucun changement détecté dans FEEDBACK.md"
            else
              git commit -m "🤖 Feedback automatique - ${{ steps.config.outputs.competence }}

              Évaluation générée automatiquement via GitHub Actions
              Compétence: ${{ steps.config.outputs.competence }}
              Niveau: ${{ steps.config.outputs.niveau }}
              
              Généré le: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
              
              # Push avec retry
              for i in {1..3}; do
                if git push; then
                  echo "✅ Feedback publié avec succès"
                  break
                else
                  echo "⚠️ Tentative $i/3 échouée, nouvelle tentative..."
                  git pull --rebase
                  sleep 2
                fi
              done
            fi
          else
            echo "⚠️ Le fichier FEEDBACK.md est vide"
          fi
        else
          echo "❌ Le fichier FEEDBACK.md n'a pas été créé"
        fi

    - name: 💬 Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          let feedbackContent = 'Génération du feedback en cours...';
          
          try {
            feedbackContent = fs.readFileSync('FEEDBACK.md', 'utf8');
            if (feedbackContent.length > 1500) {
              feedbackContent = feedbackContent.substring(0, 1500) + '\\n\\n...\\n\\n📄 **Consultez le fichier FEEDBACK.md pour le rapport complet**';
            }
          } catch (error) {
            console.log('Pas de feedback trouvé:', error);
          }
          
          await github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: '## 🤖 Évaluation Automatique\\n\\n' + feedbackContent + '\\n\\n---\\n*🌐 Évaluation automatique via GitHub Actions & Codespace*'
          });

    - name: 📊 Job Summary
      if: always()
      run: |
        echo "## 📋 Résumé de l'Évaluation Automatique" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Paramètre | Valeur |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| **Repository** | \`${{ github.repository }}\` |" >> $GITHUB_STEP_SUMMARY
        echo "| **Compétence** | ${{ steps.config.outputs.competence }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Niveau** | ${{ steps.config.outputs.niveau }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **API Status** | ${{ env.EVALUATION_SUCCESS == 'true' && '✅ Connectée' || '⚠️ Fallback utilisé' }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "FEEDBACK.md" ]; then
          echo "✅ **Status:** Feedback généré avec succès" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Status:** Problème lors de la génération" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "📅 **Généré le:** $(date)" >> $GITHUB_STEP_SUMMARY

    - name: 💬 Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          // Lire le contenu du feedback s'il existe
          const fs = require('fs');
          let feedbackContent = '';
          
          try {
            feedbackContent = fs.readFileSync('FEEDBACK.md', 'utf8');
          } catch (error) {
            feedbackContent = '⚠️ Le feedback automatique n\'a pas pu être généré. Veuillez vérifier la configuration.';
          }
          
          // Créer un commentaire sur la PR
          const comment = `## 🤖 Évaluation Automatique
          
          ${feedbackContent.substring(0, 2000)}...
          
          📄 **Voir le fichier FEEDBACK.md complet pour tous les détails**
          
          ---
          *Évaluation générée automatiquement par GitHub Actions*`;
          
          await github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

    - name: 📊 Summary
      if: always()
      run: |
        echo "## 📋 Résumé de l'Évaluation" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Repository:** ${{ github.repository }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Compétence évaluée:** ${{ steps.config.outputs.competence }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Niveau:** ${{ steps.config.outputs.niveau }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Fichiers analysés:** ${{ steps.config.outputs.files_to_analyze }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "FEEDBACK.md" ]; then
          echo "✅ **Status:** Évaluation terminée avec succès" >> $GITHUB_STEP_SUMMARY
          echo "📝 **Feedback:** Disponible dans le fichier FEEDBACK.md" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Status:** Erreur lors de l'évaluation" >> $GITHUB_STEP_SUMMARY
          echo "🔧 **Action:** Vérifier la configuration et les logs" >> $GITHUB_STEP_SUMMARY
        fi
