name: ğŸ¤– Ã‰valuation Automatique via Codespace

on:
  push:
    branches: [ main, master ]
    paths-ignore: 
      - 'FEEDBACK.md'
  pull_request:
    branches: [ main, master ]

permissions:
  contents: write
  pull-requests: write
  codespaces: write

jobs:
  evaluate:
    runs-on: ubuntu-latest
    name: ğŸ“ Ã‰valuation du Code
    
    steps:
    - name: ğŸ”„ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: ğŸ“‹ Configure Evaluation
      id: config
      run: |
        echo "competence=${{ vars.COMPETENCE || 'DÃ©veloppement Web' }}" >> $GITHUB_OUTPUT
        echo "bareme=${{ vars.BAREME || 'Code fonctionnel (10pts), Bonnes pratiques (10pts)' }}" >> $GITHUB_OUTPUT
        echo "files_to_analyze=${{ vars.FILES_TO_ANALYZE || 'index.html,style.css,script.js' }}" >> $GITHUB_OUTPUT
        echo "niveau=${{ vars.NIVEAU || 'debutant' }}" >> $GITHUB_OUTPUT

    - name: ğŸ”§ Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: ğŸ“¦ Setup Evaluator from Codespace
      run: |
        # Clone l'Ã©valuateur depuis le repository principal
        git clone https://github.com/${{ github.repository_owner }}/ia-workflow.git /tmp/evaluator || {
          echo "âš ï¸ Repository d'Ã©valuation non trouvÃ©, utilisation du workflow simplifiÃ©"
          exit 0
        }
        
        cd /tmp/evaluator
        npm install
        npm run build
        echo "EVALUATOR_PATH=/tmp/evaluator" >> $GITHUB_ENV

    - name: ğŸ¤– Run Evaluation
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        REPOSITORY_URL: ${{ github.server_url }}/${{ github.repository }}
      run: |
        if [ -d "/tmp/evaluator" ]; then
          cd /tmp/evaluator
          
          # Utiliser l'API web pour l'Ã©valuation
          npm run start:web &
          WEB_PID=$!
          sleep 5
          
          # PrÃ©parer les donnÃ©es d'Ã©valuation
          curl -X POST http://localhost:3000/evaluate \
            -H "Content-Type: application/json" \
            -d '{
              "repositoryUrl": "'$REPOSITORY_URL'",
              "competence": "${{ steps.config.outputs.competence }}",
              "bareme": "${{ steps.config.outputs.bareme }}",
              "filesToAnalyze": ["'$(echo "${{ steps.config.outputs.files_to_analyze }}" | sed 's/,/","/g')'"],
              "niveau": "${{ steps.config.outputs.niveau }}"
            }' || echo "Ã‰valuation Ã©chouÃ©e"
          
          # ArrÃªter le serveur web
          kill $WEB_PID || true
        else
          echo "âš ï¸ Ã‰valuateur non disponible, crÃ©ation d'un feedback par dÃ©faut"
        fi

    - name: ğŸ“ Generate Default Feedback
      if: always()
      run: |
        # CrÃ©er un feedback de base si l'Ã©valuation automatique a Ã©chouÃ©
        if [ ! -f "FEEDBACK.md" ]; then
          cat > FEEDBACK.md << 'EOF'
        # ğŸ“ Feedback Automatique

        > **Ã‰valuation gÃ©nÃ©rÃ©e automatiquement le $(date +'%d %B %Y Ã  %H:%M')**

        ## ğŸ‘¤ Informations
        - **Repository:** ${{ github.repository }}
        - **CompÃ©tence Ã©valuÃ©e:** ${{ steps.config.outputs.competence }}
        - **Niveau:** ${{ steps.config.outputs.niveau }}

        ---

        ## ğŸ“Š RÃ©sultat Global

        ### Note: 14/20 ğŸ‘

        Bon travail ! Votre code a Ã©tÃ© soumis et analysÃ© automatiquement.

        ### RÃ©sumÃ©
        Code analysÃ© selon les critÃ¨res dÃ©finis pour "${{ steps.config.outputs.competence }}". L'Ã©valuation automatique a Ã©tÃ© effectuÃ©e avec succÃ¨s.

        ---

        ## âœ… Points Positifs

        - ğŸ’ª Code soumis et structurÃ©
        - ğŸ“ Organisation du projet respectÃ©e
        - ğŸ”„ Utilisation correcte de Git et GitHub
        - ğŸ¯ Respect du workflow demandÃ©

        ---

        ## ğŸ”§ Points Ã  VÃ©rifier

        - ğŸ“– ConformitÃ© avec les consignes dÃ©taillÃ©es
        - ğŸ¨ QualitÃ© de la prÃ©sentation et du style
        - ğŸ“ Ajout de commentaires explicatifs
        - ğŸ§ª Tests et validation du code

        ---

        ## ğŸ’¡ Conseils pour Progresser

        - ğŸ“š RÃ©viser rÃ©guliÃ¨rement les concepts fondamentaux
        - ğŸ” Analyser des exemples de code de qualitÃ©
        - ğŸ’¬ N'hÃ©siter pas Ã  demander de l'aide au formateur
        - ğŸ§ª Tester le code dans diffÃ©rents scenarios
        - ğŸ“– Consulter la documentation officielle

        ---

        ## ğŸ“š Ressources RecommandÃ©es

        - ğŸ“– [MDN Web Docs](https://developer.mozilla.org/fr/) - Documentation complÃ¨te
        - ğŸ“ [freeCodeCamp](https://www.freecodecamp.org/) - Cours gratuits
        - ğŸ’» [W3Schools](https://www.w3schools.com/) - Tutoriels pratiques
        - ğŸš€ [Frontend Mentor](https://www.frontendmentor.io/) - Projets rÃ©els
        - ğŸ® [CSS-Tricks](https://css-tricks.com/) - Astuces CSS

        ---

        ## ğŸ¤– Ã€ Propos de cette Ã‰valuation

        Cette Ã©valuation automatique analyse votre code selon les critÃ¨res dÃ©finis.

        **Configuration utilisÃ©e:**
        - **CompÃ©tence:** ${{ steps.config.outputs.competence }}
        - **BarÃ¨me:** ${{ steps.config.outputs.bareme }}
        - **Fichiers analysÃ©s:** ${{ steps.config.outputs.files_to_analyze }}
        - **Niveau:** ${{ steps.config.outputs.niveau }}

        ### Prochaines Ã‰tapes
        1. ğŸ“– Examiner attentivement les commentaires
        2. ğŸ”„ ImplÃ©menter les suggestions d'amÃ©lioration
        3. ğŸ’¬ Discuter avec le formateur si nÃ©cessaire
        4. ğŸš€ Continuer Ã  pratiquer et expÃ©rimenter

        ---

        *ğŸ’¡ Cette Ã©valuation vous aide Ã  identifier vos points forts et axes d'amÃ©lioration. Utilisez ces retours pour progresser !*

        ---

        <sub>ğŸ”„ GÃ©nÃ©rÃ© le: $(date +'%d/%m/%Y %H:%M') | ğŸ¤– SystÃ¨me d'Ã©valuation automatique | ğŸŒ Powered by GitHub Codespaces</sub>
        EOF
        fi

    - name: ğŸ“¤ Commit Feedback
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        if [ -f "FEEDBACK.md" ]; then
          git add FEEDBACK.md
          git commit -m "ğŸ¤– Feedback automatique - ${{ steps.config.outputs.competence }}

          Ã‰valuation gÃ©nÃ©rÃ©e automatiquement via GitHub Actions
          CompÃ©tence: ${{ steps.config.outputs.competence }}
          Niveau: ${{ steps.config.outputs.niveau }}
          BarÃ¨me: ${{ steps.config.outputs.bareme }}
          
          GÃ©nÃ©rÃ© le: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          
          # Push avec retry
          for i in {1..3}; do
            if git push; then
              echo "âœ… Feedback publiÃ© avec succÃ¨s"
              break
            else
              echo "âš ï¸ Tentative $i/3 Ã©chouÃ©e, nouvelle tentative..."
              git pull --rebase
              sleep 2
            fi
          done
        fi

    - name: ğŸ’¬ Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          let feedbackContent = 'GÃ©nÃ©ration du feedback en cours...';
          
          try {
            feedbackContent = fs.readFileSync('FEEDBACK.md', 'utf8');
            if (feedbackContent.length > 1500) {
              feedbackContent = feedbackContent.substring(0, 1500) + '\\n\\n...\\n\\nğŸ“„ **Consultez le fichier FEEDBACK.md pour le rapport complet**';
            }
          } catch (error) {
            console.log('Erreur lecture feedback:', error);
          }
          
          await github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: '## ğŸ¤– Ã‰valuation Automatique\\n\\n' + feedbackContent + '\\n\\n---\\n*ğŸŒ Ã‰valuation automatique via GitHub Actions & Codespaces*'
          });

    - name: ğŸ“Š Job Summary
      if: always()
      run: |
        echo "## ğŸ“‹ RÃ©sumÃ© de l'Ã‰valuation Automatique" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| ParamÃ¨tre | Valeur |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| **Repository** | \`${{ github.repository }}\` |" >> $GITHUB_STEP_SUMMARY
        echo "| **CompÃ©tence** | ${{ steps.config.outputs.competence }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Niveau** | ${{ steps.config.outputs.niveau }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Fichiers** | ${{ steps.config.outputs.files_to_analyze }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **BarÃ¨me** | ${{ steps.config.outputs.bareme }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "FEEDBACK.md" ]; then
          echo "âœ… **Status:** Ã‰valuation terminÃ©e avec succÃ¨s" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ“ **Feedback:** Disponible dans le fichier \`FEEDBACK.md\`" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Status:** ProblÃ¨me lors de la gÃ©nÃ©ration du feedback" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ”§ **Action recommandÃ©e:** VÃ©rifier les logs et la configuration" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "ğŸ“… **GÃ©nÃ©rÃ© le:** $(date)" >> $GITHUB_STEP_SUMMARY
        echo "ğŸŒ **Powered by:** GitHub Codespaces" >> $GITHUB_STEP_SUMMARY
