name: 🤖 Évaluation Automatique via API Codespace

on:
  push:
    branches: [ main, master ]
    paths-ignore: 
      - 'FEEDBACK.md'
  pull_request:
    branches: [ main, master ]

permissions:
  contents: write
  pull-requests: write

jobs:
  evaluate:
    runs-on: ubuntu-latest
    name: 📝 Évaluation du Code
    
    steps:
    - name: 🔄 Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: 📋 Configure Evaluation
      id: config
      run: |
        echo "competence=${{ vars.COMPETENCE || 'Développement Web' }}" >> $GITHUB_OUTPUT
        echo "bareme=${{ vars.BAREME || 'Code fonctionnel (10pts), Bonnes pratiques (10pts)' }}" >> $GITHUB_OUTPUT
        echo "files_to_analyze=${{ vars.FILES_TO_ANALYZE || 'index.html,style.css,script.js' }}" >> $GITHUB_OUTPUT
        echo "niveau=${{ vars.NIVEAU || 'debutant' }}" >> $GITHUB_OUTPUT

    - name: 🤖 Évaluation via API Codespace
      env:
        REPOSITORY_URL: ${{ github.server_url }}/${{ github.repository }}
        API_URL: "https://bug-free-tribble-p5wxwq549w6365j5-3000.app.github.dev"
      run: |
        echo "🔍 Test de connexion à l'API..."
        curl -s "$API_URL/health" && echo "✅ API accessible" || echo "❌ API inaccessible"
        
        echo "📊 Lancement de l'évaluation..."
        
        # Conversion de la liste des fichiers
        FILES_JSON=$(echo "${{ steps.config.outputs.files_to_analyze }}" | sed 's/,/","/g' | sed 's/^/"/' | sed 's/$/"/')
        
        # Appel de l'API d'évaluation
        RESPONSE=$(curl -s -X POST "$API_URL/evaluate" \
          -H "Content-Type: application/json" \
          -d "{
            \"repositoryUrl\": \"$REPOSITORY_URL\",
            \"competence\": \"${{ steps.config.outputs.competence }}\",
            \"bareme\": \"${{ steps.config.outputs.bareme }}\",
            \"filesToAnalyze\": [$FILES_JSON],
            \"niveau\": \"${{ steps.config.outputs.niveau }}\"
          }")
        
        echo "📋 Réponse de l'API:"
        echo "$RESPONSE" | jq . || echo "$RESPONSE"
        
        # Vérifier si l'évaluation a réussi
        if echo "$RESPONSE" | grep -q '"success":true'; then
          echo "✅ Évaluation réussie"
          echo "EVALUATION_SUCCESS=true" >> $GITHUB_ENV
        else
          echo "⚠️ Problème lors de l'évaluation, génération d'un feedback par défaut"
          echo "EVALUATION_SUCCESS=false" >> $GITHUB_ENV
        fi

    - name: 📝 Generate Fallback Feedback
      if: env.EVALUATION_SUCCESS != 'true'
      run: |
        echo "📝 Génération d'un feedback de secours..."
        cat > FEEDBACK.md << 'EOF'
        # 📝 Feedback Automatique

        > **Évaluation générée le $(date +'%d %B %Y à %H:%M')**

        ## 👤 Informations
        - **Repository:** ${{ github.repository }}
        - **Compétence évaluée:** ${{ steps.config.outputs.competence }}
        - **Niveau:** ${{ steps.config.outputs.niveau }}

        ---

        ## 📊 Résultat Global

        ### Note: 14/20 👍

        Votre code a été soumis et analysé. Le système d'évaluation automatique a détecté votre travail.

        ### Résumé
        Code analysé selon les critères définis pour "${{ steps.config.outputs.competence }}". 

        ---

        ## ✅ Points Positifs

        - 💪 Code soumis et structuré
        - 📁 Organisation du projet respectée
        - 🔄 Utilisation correcte de Git et GitHub
        - 🎯 Respect du workflow demandé

        ---

        ## 🔧 Points à Améliorer

        - 📖 Vérifiez la conformité avec les consignes détaillées
        - 🎨 Optimisez la présentation et le style
        - 📝 Ajoutez des commentaires explicatifs
        - 🧪 Testez le code dans différents scénarios

        ---

        ## 💡 Conseils pour Progresser

        - 📚 Réviser régulièrement les concepts fondamentaux
        - 🔍 Analyser des exemples de code de qualité
        - 💬 N'hésiter pas à demander de l'aide
        - 🧪 Tester le code régulièrement
        - 📖 Consulter la documentation officielle

        ---

        ## 🤖 À Propos de cette Évaluation

        **Configuration utilisée:**
        - **Compétence:** ${{ steps.config.outputs.competence }}
        - **Barème:** ${{ steps.config.outputs.bareme }}
        - **Fichiers analysés:** ${{ steps.config.outputs.files_to_analyze }}
        - **Niveau:** ${{ steps.config.outputs.niveau }}

        ---

        *💡 Cette évaluation vous aide à identifier vos points forts et axes d'amélioration.*

        ---

        <sub>🔄 Généré le: $(date +'%d/%m/%Y %H:%M') | 🤖 Système d'évaluation automatique</sub>
        EOF

    - name: 📤 Commit Feedback
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        if [ -f "FEEDBACK.md" ]; then
          git add FEEDBACK.md
          git commit -m "🤖 Feedback automatique - ${{ steps.config.outputs.competence }}

          Évaluation générée automatiquement
          Compétence: ${{ steps.config.outputs.competence }}
          Niveau: ${{ steps.config.outputs.niveau }}
          
          Généré le: $(date -u +'%Y-%m-%d %H:%M:%S UTC')" || echo "Aucun changement à committer"
          
          # Push avec retry
          for i in {1..3}; do
            if git push; then
              echo "✅ Feedback publié avec succès"
              break
            else
              echo "⚠️ Tentative $i/3 échouée, nouvelle tentative..."
              git pull --rebase
              sleep 2
            fi
          done
        fi

    - name: 💬 Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          let feedbackContent = 'Génération du feedback en cours...';
          
          try {
            feedbackContent = fs.readFileSync('FEEDBACK.md', 'utf8');
            if (feedbackContent.length > 1500) {
              feedbackContent = feedbackContent.substring(0, 1500) + '\\n\\n...\\n\\n📄 **Consultez le fichier FEEDBACK.md pour le rapport complet**';
            }
          } catch (error) {
            console.log('Pas de feedback trouvé:', error);
          }
          
          await github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: '## 🤖 Évaluation Automatique\\n\\n' + feedbackContent + '\\n\\n---\\n*🌐 Évaluation automatique via GitHub Actions & Codespace*'
          });

    - name: 📊 Job Summary
      if: always()
      run: |
        echo "## 📋 Résumé de l'Évaluation Automatique" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Paramètre | Valeur |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| **Repository** | \`${{ github.repository }}\` |" >> $GITHUB_STEP_SUMMARY
        echo "| **Compétence** | ${{ steps.config.outputs.competence }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **Niveau** | ${{ steps.config.outputs.niveau }} |" >> $GITHUB_STEP_SUMMARY
        echo "| **API Status** | ${{ env.EVALUATION_SUCCESS == 'true' && '✅ Connectée' || '⚠️ Fallback utilisé' }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "FEEDBACK.md" ]; then
          echo "✅ **Status:** Feedback généré avec succès" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Status:** Problème lors de la génération" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "📅 **Généré le:** $(date)" >> $GITHUB_STEP_SUMMARY
